{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02ba455-74ce-4239-8945-30c5de8424e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters injected by Papermill or default fallback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    parameters\n",
    "except NameError:\n",
    "    parameters = {\"cwd\": \".\", \"airflow\": True}  # Add \"airflow\": True default to avoid preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2943378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(f\"üì• Working directory set to: {cwd}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e6a68-7b72-4434-9e08-c5ef29378cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    month_str\n",
    "except NameError:\n",
    "    today = datetime.today()\n",
    "    first_of_this_month = datetime(today.year, today.month, 1)\n",
    "    last_of_prev_month = first_of_this_month - timedelta(days=1)\n",
    "    first_of_prev_month = datetime(last_of_prev_month.year, last_of_prev_month.month, 1)\n",
    "    month_str = first_of_prev_month.strftime(\"%Y_%m\")\n",
    "    logger.info(f\"üìÖ Using month_str: {month_str}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015fe45-313f-4068-9c66-4a879b513534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input path to national monthly weather data (produced by transform)\n",
    "input_path = os.path.join(cwd, f\"weather_national_monthly_{month_str}.csv\")\n",
    "\n",
    "if not os.path.exists(input_path):\n",
    "    logger.error(f\"‚ùå Input file not found: {input_path}\")\n",
    "    raise FileNotFoundError(f\"Input file not found: {input_path}\")\n",
    "\n",
    "logger.info(f\"‚úÖ Input file found: {input_path}\")\n",
    "\n",
    "# Output path for combined/loading data\n",
    "output_path = os.path.join(cwd, \"selected_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e3031-13d7-4744-b0cf-21141a49c335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Appended new month at bottom of file.\n"
     ]
    }
   ],
   "source": [
    "# National-level input and output file paths\n",
    "input_path_national = os.path.join(cwd, f\"weather_national_monthly_{month_str}.csv\")\n",
    "output_path_national = os.path.join(cwd, \"selected_data.csv\")\n",
    "\n",
    "if not os.path.exists(input_path_national):\n",
    "    logger.error(f\"‚ùå National input file not found: {input_path_national}\")\n",
    "    raise FileNotFoundError(f\"National input file not found: {input_path_national}\")\n",
    "\n",
    "logger.info(f\"‚úÖ Found national input file: {input_path_national}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba7b38-0d3f-4da0-b1a6-96d8d67a45e0",
   "metadata": {},
   "source": [
    "## Append/Load National Monthly Data to final destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803680ea-5d41-46fc-ba61-7fa18b235ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load national data \n",
    "national_df = pd.read_csv(input_path_national)\n",
    "\n",
    "# Add new empty target column\n",
    "national_df[\"ddd_demand\"] = np.nan\n",
    "\n",
    "# Reorder columns\n",
    "cols_national = [\n",
    "    \"avg_temp_max\", \"avg_temp_min\", \"avg_humidity\",\n",
    "    \"total_precipitation\", \"total_sunshine_hours\", \"ddd_demand\"\n",
    "]\n",
    "national_df = national_df[cols_national]\n",
    "\n",
    "logger.info(f\"‚úÖ Loaded national data with shape {national_df.shape}\")\n",
    "\n",
    "# Append or create output\n",
    "if os.path.exists(output_path_national):\n",
    "    existing_df = pd.read_csv(output_path_national)\n",
    "    match_cols = cols_national[:-1]  # exclude 'ddd_demand'\n",
    "\n",
    "    mask = (existing_df[match_cols] == national_df.loc[0, match_cols]).all(axis=1)\n",
    "    if mask.any():\n",
    "        logger.info(f\"‚ö†Ô∏è Data for {month_str} already exists in national dataset. Skipping append.\")\n",
    "    else:\n",
    "        combined_df = pd.concat([existing_df, national_df], ignore_index=True)\n",
    "        combined_df.to_csv(output_path_national, index=False)\n",
    "        logger.info(f\"‚úÖ Appended new month data to {output_path_national}\")\n",
    "else:\n",
    "    national_df.to_csv(output_path_national, index=False)\n",
    "    logger.info(f\"üì¶ Created new national data file: {output_path_national}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302d48b-a8a0-4e84-b83f-9ea1ca5e1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# District-level input and output paths\n",
    "input_path_district = os.path.join(cwd, f\"weather_district_monthly_{month_str}.csv\")\n",
    "output_path_district = os.path.join(cwd, \"malaria_historical.csv\")\n",
    "\n",
    "if not os.path.exists(input_path_district):\n",
    "    logger.error(f\"‚ùå District input file not found: {input_path_district}\")\n",
    "    raise FileNotFoundError(f\"District input file not found: {input_path_district}\")\n",
    "\n",
    "logger.info(f\"‚úÖ Found district input file: {input_path_district}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8bf85b-5eb6-4d76-8720-78a0131946e0",
   "metadata": {},
   "source": [
    "## Append/Load District Monthly Data to final destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b8885-8a73-4b68-a656-e519d54ebc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üö´ Data already exists for the following district-month combinations:\n",
      "\n",
      "     district  year  month\n",
      "         Abim  2025      6\n",
      "     Adjumani  2025      6\n",
      "        Agago  2025      6\n",
      "     Alebtong  2025      6\n",
      "     Amolatar  2025      6\n",
      "       Amudat  2025      6\n",
      "       Amuria  2025      6\n",
      "        Amuru  2025      6\n",
      "         Apac  2025      6\n",
      "         Arua  2025      6\n",
      "       Budaka  2025      6\n",
      "       Bududa  2025      6\n",
      "       Bugiri  2025      6\n",
      "      Bugweri  2025      6\n",
      "      Buhweju  2025      6\n",
      "       Buikwe  2025      6\n",
      "      Bukedea  2025      6\n",
      " Bukomansimbi  2025      6\n",
      "        Bukwo  2025      6\n",
      "    Bulambuli  2025      6\n",
      "      Buliisa  2025      6\n",
      "   Bundibugyo  2025      6\n",
      "   Bunyangabu  2025      6\n",
      "        Busia  2025      6\n",
      "     Butaleja  2025      6\n",
      "    Butambala  2025      6\n",
      "       Butebo  2025      6\n",
      "       Buvuma  2025      6\n",
      "      Buyende  2025      6\n",
      "       Dokolo  2025      6\n",
      "         Gulu  2025      6\n",
      "        Hoima  2025      6\n",
      "       Ibanda  2025      6\n",
      "       Iganga  2025      6\n",
      "     Isingiro  2025      6\n",
      "        Jinja  2025      6\n",
      "       Kabale  2025      6\n",
      "     Kabarole  2025      6\n",
      "  Kaberamaido  2025      6\n",
      "       Kagadi  2025      6\n",
      "     Kakumiro  2025      6\n",
      "    Kalangala  2025      6\n",
      "       Kaliro  2025      6\n",
      "      Kalungu  2025      6\n",
      "      Kampala  2025      6\n",
      "       Kamuli  2025      6\n",
      "     Kamwenge  2025      6\n",
      "      Kanungu  2025      6\n",
      "    Kapchorwa  2025      6\n",
      "       Kasese  2025      6\n",
      "      Katakwi  2025      6\n",
      "      Kayunga  2025      6\n",
      "      Kibaale  2025      6\n",
      "       Kiboga  2025      6\n",
      "       Kibuku  2025      6\n",
      "     Kiruhura  2025      6\n",
      "  Kiryandongo  2025      6\n",
      "       Kisoro  2025      6\n",
      "       Kitgum  2025      6\n",
      "       Koboko  2025      6\n",
      "         Kole  2025      6\n",
      "       Kotido  2025      6\n",
      "         Kumi  2025      6\n",
      "       Kwania  2025      6\n",
      "        Kween  2025      6\n",
      "   Kyankwanzi  2025      6\n",
      "     Kyegegwa  2025      6\n",
      "     Kyenjojo  2025      6\n",
      "        Lamwo  2025      6\n",
      "         Lira  2025      6\n",
      "        Luuka  2025      6\n",
      "       Luwero  2025      6\n",
      "       Lwengo  2025      6\n",
      "    Lyantonde  2025      6\n",
      "      Manafwa  2025      6\n",
      "      Maracha  2025      6\n",
      "       Masaka  2025      6\n",
      "      Masindi  2025      6\n",
      "       Mayuge  2025      6\n",
      "        Mbale  2025      6\n",
      "      Mbarara  2025      6\n",
      "      Mitooma  2025      6\n",
      "      Mityana  2025      6\n",
      "       Moroto  2025      6\n",
      "         Moyo  2025      6\n",
      "        Mpigi  2025      6\n",
      "      Mubende  2025      6\n",
      "       Mukono  2025      6\n",
      "Nakapiripirit  2025      6\n",
      "     Nakaseke  2025      6\n",
      "  Nakasongola  2025      6\n",
      "    Namayingo  2025      6\n",
      "   Namisindwa  2025      6\n",
      "    Namutumba  2025      6\n",
      "        Napak  2025      6\n",
      "        Nebbi  2025      6\n",
      "        Ngora  2025      6\n",
      "      Ntoroko  2025      6\n",
      "     Ntungamo  2025      6\n",
      "        Nwoya  2025      6\n",
      "        Omoro  2025      6\n",
      "        Otuke  2025      6\n",
      "         Oyam  2025      6\n",
      "        Pader  2025      6\n",
      "      Pakwach  2025      6\n",
      "      Pallisa  2025      6\n",
      "      Rubanda  2025      6\n",
      "     Rubirizi  2025      6\n",
      "       Rukiga  2025      6\n",
      "    Rukungiri  2025      6\n",
      "    Sembabule  2025      6\n",
      "       Serere  2025      6\n",
      "       Sheema  2025      6\n",
      "      Sironko  2025      6\n",
      "       Soroti  2025      6\n",
      "       Tororo  2025      6\n",
      "       Wakiso  2025      6\n",
      "        Yumbe  2025      6\n",
      "        Zombo  2025      6\n",
      "\n",
      "‚ÑπÔ∏è Skipping append to avoid duplicate entries. No changes were made.\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Load new district monthly data\n",
    "district_df = pd.read_csv(input_path_district)\n",
    "\n",
    "# Add empty mal_cases column\n",
    "district_df[\"mal_cases\"] = pd.NA\n",
    "\n",
    "# Reorder columns for consistency\n",
    "cols_district = [\n",
    "    \"year\", \"month\", \"district\", \"mal_cases\",\n",
    "    \"avg_temp_max\", \"avg_temp_min\", \"avg_humidity\",\n",
    "    \"total_precipitation\", \"total_sunshine_hours\"\n",
    "]\n",
    "district_df = district_df[cols_district]\n",
    "\n",
    "# Load historical district data if exists\n",
    "if os.path.exists(output_path_district):\n",
    "    historical_df = pd.read_csv(output_path_district)\n",
    "\n",
    "    # Rename columns if needed\n",
    "    historical_df = historical_df.rename(columns={\n",
    "        \"sum_precipitation\": \"total_precipitation\",\n",
    "        \"sum_sunshine_hours\": \"total_sunshine_hours\"\n",
    "    })\n",
    "\n",
    "    if \"mal_cases\" not in historical_df.columns:\n",
    "        historical_df[\"mal_cases\"] = pd.NA\n",
    "\n",
    "    # Reorder to match district_df columns\n",
    "    historical_df = historical_df[cols_district]\n",
    "\n",
    "    # Check for duplicates (district, year, month)\n",
    "    duplicates = pd.merge(\n",
    "        district_df[[\"district\", \"year\", \"month\"]],\n",
    "        historical_df[[\"district\", \"year\", \"month\"]],\n",
    "        on=[\"district\", \"year\", \"month\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    if not duplicates.empty:\n",
    "        logger.info(f\"‚ö†Ô∏è Data for {month_str} already exists for some districts. Skipping append for duplicates.\")\n",
    "        logger.info(f\"Duplicate entries:\\n{duplicates.to_string(index=False)}\")\n",
    "    else:\n",
    "        # Append and save\n",
    "        combined_df = pd.concat([historical_df, district_df], ignore_index=True)\n",
    "        combined_df = combined_df.sort_values([\"district\", \"year\", \"month\"]).reset_index(drop=True)\n",
    "        combined_df.to_csv(output_path_district, index=False)\n",
    "        logger.info(f\"‚úÖ Appended district data and saved to {output_path_district}\")\n",
    "else:\n",
    "    # No historical data yet ‚Äî save new data\n",
    "    district_df = district_df.sort_values([\"district\", \"year\", \"month\"]).reset_index(drop=True)\n",
    "    district_df.to_csv(output_path_district, index=False)\n",
    "    logger.info(f\"üì¶ Created new district data file: {output_path_district}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60496e90-37cf-40b3-b31a-f17c8e37dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not parameters.get(\"airflow\", False):\n",
    "    logger.info(\"üìä Preview of national data:\")\n",
    "    print(national_df.head())\n",
    "\n",
    "    logger.info(\"üìä Preview of district data:\")\n",
    "    print(district_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
