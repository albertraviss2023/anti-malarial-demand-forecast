{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "948b15a1",
   "metadata": {},
   "source": [
    "# Anti-Malarial Demand Forecasting Analysis\n",
    "\n",
    "This notebook tests the Airflow DAG submission by performing a simple demand forecasting analysis for anti-malarial drugs. It:\n",
    "- Reads sample data from a MinIO bucket.\n",
    "- Processes data using PySpark.\n",
    "- Writes results to an Apache Iceberg table.\n",
    "- Queries the Iceberg table using Trino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b745c059",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters injected by Papermill\n",
    "minio_bucket = 'demand-data'  # Default value, overridden by DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d98c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, lit\n",
    "from minio import Minio\n",
    "import trino\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize SparkSession with Iceberg configurations\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('DemandForecasting') \\\n",
    "    .config('spark.master', 'spark://spark-master:7077') \\\n",
    "    .config('spark.jars.packages', 'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1,org.apache.kafka:kafka-clients:3.6.2') \\\n",
    "    .config('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions') \\\n",
    "    .config('spark.sql.catalog.iceberg', 'org.apache.iceberg.spark.SparkCatalog') \\\n",
    "    .config('spark.sql.catalog.iceberg.type', 'rest') \\\n",
    "    .config('spark.sql.catalog.iceberg.uri', 'http://iceberg-rest:8181') \\\n",
    "    .config('spark.sql.catalog.iceberg.warehouse', 's3a://iceberg-warehouse/') \\\n",
    "    .config('spark.hadoop.fs.s3a.endpoint', 'http://minio:9000') \\\n",
    "    .config('spark.hadoop.fs.s3a.access.key', 'minioadmin') \\\n",
    "    .config('spark.hadoop.fs.s3a.secret.key', 'minioadmin') \\\n",
    "    .config('spark.hadoop.fs.s3a.path.style.access', 'true') \\\n",
    "    .config('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Initialize MinIO client\n",
    "minio_client = Minio(\n",
    "    'minio:9000',\n",
    "    access_key='minioadmin',\n",
    "    secret_key='minioadmin',\n",
    "    secure=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4581aee",
   "metadata": {},
   "source": [
    "## Step 1: Create Sample Data in MinIO\n",
    "\n",
    "Create a sample CSV file with anti-malarial drug demand data and upload it to the specified MinIO bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62326da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "sample_data = pd.DataFrame({\n",
    "    'region': ['East Africa', 'West Africa', 'Southern Africa', 'East Africa', 'West Africa'],\n",
    "    'drug': ['Artemether', 'Artemether', 'Lumefantrine', 'Lumefantrine', 'Artemether'],\n",
    "    'year': [2023, 2023, 2023, 2024, 2024],\n",
    "    'demand_units': [1000, 1500, 800, 1200, 1700]\n",
    "})\n",
    "\n",
    "# Save to temporary CSV\n",
    "sample_csv_path = '/tmp/sample_demand_data.csv'\n",
    "sample_data.to_csv(sample_csv_path, index=False)\n",
    "\n",
    "# Create bucket if it doesn't exist\n",
    "if not minio_client.bucket_exists(minio_bucket):\n",
    "    minio_client.make_bucket(minio_bucket)\n",
    "\n",
    "# Upload sample data to MinIO\n",
    "minio_client.fput_object(\n",
    "    minio_bucket,\n",
    "    'sample_demand_data.csv',\n",
    "    sample_csv_path\n",
    ")\n",
    "print(f'Uploaded sample data to {minio_bucket}/sample_demand_data.csv')\n",
    "\n",
    "# Clean up temporary file\n",
    "os.remove(sample_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953232d",
   "metadata": {},
   "source": [
    "## Step 2: Read and Process Data with Spark\n",
    "\n",
    "Read the CSV file from MinIO, calculate average demand per region and drug, and create a simple forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6dbaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV from MinIO\n",
    "input_path = f's3a://{minio_bucket}/sample_demand_data.csv'\n",
    "df = spark.read.option('header', 'true').csv(input_path)\n",
    "\n",
    "# Calculate average demand per region and drug\n",
    "avg_demand = df.groupBy('region', 'drug').agg(avg('demand_units').alias('avg_demand_units'))\n",
    "\n",
    "# Create forecast (e.g., increase by 10% for next year)\n",
    "forecast_df = avg_demand.withColumn('forecast_year', lit(2025)) \\\n",
    "                       .withColumn('forecast_demand_units', col('avg_demand_units') * 1.10)\n",
    "\n",
    "forecast_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128c17e",
   "metadata": {},
   "source": [
    "## Step 3: Write Results to Iceberg Table\n",
    "\n",
    "Write the forecast data to an Iceberg table named `demand_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e39e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to Iceberg table\n",
    "forecast_df.write.mode('overwrite').saveAsTable('iceberg.demand_table')\n",
    "print('Wrote forecast data to iceberg.demand_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04be5262",
   "metadata": {},
   "source": [
    "## Step 4: Verify with Trino Query\n",
    "\n",
    "Query the Iceberg table using Trino to ensure data was written correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Trino\n",
    "conn = trino.dbapi.connect(\n",
    "    host='trino-coordinator',\n",
    "    port=8084,\n",
    "    user='trino',\n",
    "    catalog='iceberg',\n",
    "    schema='default'\n",
    ")\n",
    "\n",
    "# Execute query\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('SELECT * FROM iceberg.demand_table LIMIT 5')\n",
    "results = cursor.fetchall()\n",
    "\n",
    "# Display results\n",
    "print('Trino query results:')\n",
    "for row in results:\n",
    "    print(row)\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cde194",
   "metadata": {},
   "source": [
    "## Step 5: Cleanup\n",
    "\n",
    "Stop the Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae559932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()\n",
    "print('Spark session stopped')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
